{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, isdir\n",
    "from os import makedirs\n",
    "import einops\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import model\n",
    "from coco_fake_dataset import COCOFakeDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco2014_path = join(\"..\", \"..\", \"datasets\", \"coco2014\")\n",
    "coco_fake_path = join(\"..\", \"..\", \"datasets\", \"fake_coco\")\n",
    "images_path = join(\".\", \"images\")\n",
    "pretrained_model_path = join(\"images\", \"coco_fake_S_epoch=4-train_acc=0.93-val_acc=0.93.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = COCOFakeDataset(\n",
    "        coco2014_path=coco2014_path,\n",
    "        coco_fake_path=coco_fake_path,\n",
    "        split=\"val\",\n",
    "        mode=\"single\",\n",
    "        resolution=224,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.BNext4DFR.load_from_checkpoint(pretrained_model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the images dir\n",
    "from os import makedirs\n",
    "if not isdir(images_path):\n",
    "    makedirs(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    import torch\n",
    "    import timm\n",
    "    # adds the new channels to the image\n",
    "    image_augmented = net.add_new_channels(batch[\"image\"])\n",
    "    image_adapted = net.adapter(image_augmented).detach().cpu()\n",
    "    image_adapted = (image_adapted - torch.as_tensor(timm.data.constants.IMAGENET_DEFAULT_MEAN).view(1, -1, 1, 1)) / torch.as_tensor(timm.data.constants.IMAGENET_DEFAULT_STD).view(1, -1, 1, 1)\n",
    "    features = net.base_model(image_adapted)[0]\n",
    "    image_adapted = einops.rearrange(image_adapted[0], \"c h w -> h w c\")\n",
    "    rgb_image = einops.rearrange(image_augmented[0, :3], \"c h w -> h w c\")\n",
    "    fft_image = image_augmented[0, -2]\n",
    "    lbp_image = image_augmented[0, -1]\n",
    "    # plots each channel of the augmented image\n",
    "    for image, title in [\n",
    "        (rgb_image, \"rgb\"),\n",
    "        (fft_image, \"fft\"),\n",
    "        (lbp_image, \"lbp\"),\n",
    "        (image_adapted, \"adapted\"),\n",
    "        ]:\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(join(images_path, f\"{title}.png\"), bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
