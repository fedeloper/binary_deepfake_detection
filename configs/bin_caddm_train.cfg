crop_face:
  face_width: 80
  output_size: 224
  scale: 0.9

adm_det:
  min_dim: 224
  aspect_ratios: [[1], [1], [1], [1]]
  feature_maps: [7, 5, 3, 1]
  steps: [32, 45, 75, 224]
  min_sizes: [40, 80, 120, 224]
  max_sizes: [80, 120, 160, 224]
  clip: True
  variance: [0.1]
  name: "deepfake"

sliding_win:
  prior_bbox: [[40, 80], [80, 120], [120, 160], [224, 224]]

det_loss:
  num_classes: 2
  overlap_thresh: 0.9
  prior_for_matching: True
  bkg_label: 0
  neg_mining: True
  neg_pos: 2
  neg_overlap: 0.5
  encode_target: False
  use_gpu: True

dataset:
  coco2014_path: "../../datasets/coco2014"
  coco_fake_path: "../../datasets/fake_coco"
  labels: 2
  img_path: "./train_images"
  ld_path: "./train_images/ldm.json"

model:
  backbone: "BNext-T"
  save_path: "./checkpoints"

train:
  batch_size: 64
  mixed_precision: True
  epoch_num: 25
  accumulation_batches: 2
  limit_train_batches: 0.1
  resolution: 224
